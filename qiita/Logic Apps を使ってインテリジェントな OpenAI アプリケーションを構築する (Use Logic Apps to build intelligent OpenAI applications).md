https://techcommunity.microsoft.com/t5/azure-integration-services-blog/use-logic-apps-to-build-intelligent-openai-applications/ba-p/4014121

「Use Logic Apps to build intelligent OpenAI applications」という記事のざっくりとした翻訳です。

## コンテキスト

>エンタープライズ・アプリケーションにおけるデータとのインタラクションは、ますます広まりつつあります。開発者は現在この目的のため RAG（Retrieval Augmented Generation）モデルを多く採用しています。この方法は、OpenAIとCognitive Searchのようなベクトルストレージ技術を統合し、ユーザーがその形式に関係なく、エンタープライズデータと自然言語で会話することを可能にします。

GitHubのサンプル:

https://github.com/Azure-Samples/azure-search-openai-demo




## コードフルな手段

> 洗練されたアプリケーションの構築には、通常、いくつかの重要なステップとなるビルディング・ブロックを組み合わせる必要があります。主に、動的な取り込みパイプラインと、ベクターデータベースや大規模言語モデル（LLM）と通信できるチャット インターフェースの作成がそれです。様々なコンポーネントを組み合わせることで、データ取り込みプロセスを実行するだけでなく、チャットインターフェース用の堅牢なバックエンドを提供することもできます。このバックエンドは、プロンプトの送信を容易にし、対話中に信頼できる応答を生成します。しかし、コードでこれらのすべての要素を管理し、制御することは、非常に困難な場合があります。

## Logic Appsによるコードレス・アプローチ

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/93824/9860c33f-9bb9-81a1-8ca1-2a08df0bb1a6.png)

> このコンテキストでは、バックエンド管理を簡素化するLogic Appsの役割に主眼が置かれています。Logic Appsは、あらかじめ構築されたコネクターをビルディング ブロックとして提供し、バックエンドのプロセスを合理化します。これにより、データのソーシングのみに集中し、プロンプトを受信したときに、検索によって最新の情報が得られるようにすることができます。Azure OpenAI + Cognitive Servicesで使用されているサンプルの例を見てみましょう。

	
> Azure Open AI とAI Search の新しいサービス プロバイダ コネクタを紹介できることを嬉しく思います。このコネクタは、開発者がデータを取り込み、簡単なチャット会話を促進するアプリケーションを作成できるように設計されています。よりよく理解するために、バックエンドロジックを2つの主要なワークフローに分解してみましょう

### 取り込み ワークフロー

> 開発者は、SharePoint や OneDrive のような選択したストレージ システムに新しいファイルが到着したときなど、定期的または特定のイベントに応じて PDF ファイルを取得するトリガーを設定することができます。以下は、その取り込みがどのように見えるかについて、簡略化したワークフロー・プロセスです。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/93824/70a9ba9e-4335-6b65-00e3-fb73d2ae4a63.png)

 
> データの取得： サードパーティのストレージシステムからデータを取得する。
データのトークン化： このシナリオでは、PDFドキュメントをトークン化する。
埋め込みデータの生成： Azure OpenAIを利用して埋め込みデータを作成する。
ドキュメントのインデックス化： AI Searchを使って、ドキュメントにインデックスを付ける。

							
> あらゆるデータソースでこのパターンを実装することで、開発者は取り込みパイプラインを構築する際の時間と労力を大幅に節約できます。このアプローチはコーディング面を単純化するだけでなく、ワークフローが効果的な認証、モニタリング、デプロイメント プロセスを備えていることを保証します。本質的には、Logic App (Standard)が現在提供している全ての利点が集約されています。

### チャット ワークフロー

> データはベクターデータベースに取り込まれ続けるため、ユーザーが質問したときに、ロジックアプリのバックエンドがプロンプトを処理し、信頼できる応答を生成できるように、簡単に検索できるようにする必要があります。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/93824/e4df6e2a-96ba-3fb0-16c2-5b51c3d4a334.png)

> プロンプトのキャプチャ： HTTPリクエストトリガーを介してJSONをキャプチャする。
モデルのトレーニング： サンプルレスポンスへの適応（GitHubの例をモデル化）
クエリーの生成： ベクトルデータベースの検索クエリの作成
埋め込み変換： クエリをベクトル埋め込みに変換
ベクトル検索操作： 優先データベースでの検索実行
プロンプト作成とチャット補完： プロンプトを作成し、チャット補完APIと接続するために簡単なJavaScriptを使用し、チャット会話で信頼性の高い応答を保証します。

> エンベッディングの生成、トークン化からベクトル検索まで、プロセスのすべてのステップは、ステートレスワークフローによる迅速なパフォーマンスを約束するだけでなく、AIがデータファイルからすべての重要な洞察と情報をシームレスに抽出することを保証します。

## お試しください

> 新しいコネクタは現在プライベートプレビュー中です。お気軽にお試しください。2024年1月にパブリックプレビューを行う予定です。
